{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = Path(os.getcwd())\n",
    "kaggle_dir = Path('kaggle/input/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = local_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = notebook_dir / 'llm-detect-ai-generated-text'\n",
    "test_essays = pd.read_csv(data_dir / 'test_essays.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARCHITECTURE = 'microsoft/deberta-v3-xsmall'\n",
    "INPUT_LENGTH = 1024\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_cpu(text, tokenizer, model, max_length):\n",
    "    # Ensure the model is in evaluation mode and on CPU\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=max_length, truncation=True, padding='max_length')\n",
    "    inputs = {k: v.cpu() for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('models/test_model')\n",
    "tokenizer = AutoTokenizer.from_pretrained('models/deberta_tokenizer')\n",
    "for i, row in test_essays.iterrows():\n",
    "    text_to_predict = row['text']\n",
    "    probabilities = predict_on_cpu(text_to_predict, tokenizer, model, INPUT_LENGTH)\n",
    "    test_essays.loc[i, 'generated'] = probabilities[0, 1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.2788e-04, 9.9957e-01]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"In a world where the hum of engines and the honk of car horns have become the background noise to our daily lives, it's time we confront the question: What if we let go of the steering wheel? Let's face it, cars, as convenient as they are, spell a trilogy of trouble‚Äîpollution, expense, and health concerns. It's high time we put our foot down, not on the gas pedal, but on the brakes of our car-centric culture.\n",
    "\n",
    "Take Vauban, Germany, for instance, a beacon of car-less suburban life where residents' quality of life hasn't diminished; it's flourished. \"When I had a car I was always tense. I'm much happier this way,\" says Heidrun Walter, a resident of Vauban. The simplicity of walking and cycling replaces hours of snailing in traffic and the mental stress that accompanies it. And it isn't just a single utopian example; cities worldwide are increasingly adopting similar \"smart planning\" approaches to build communities less dependent on cars. These methods not only promise a cleaner, quieter environment but bring back the joy of community that's often lost in the roars of engines.\n",
    "\n",
    "Now, look at Paris, with its surreal sights often shrouded in smog so thick it chokes the romance right out of the air. The city's recent partial driving ban, while drastic, dramatically reduced congestion by 60 percent and, more importantly, cleared the pollution for a time. It's a stark reminder that the air we breathe is precious and points to the need for sustainable solutions. Even the USA, the land that practically added wheels to the American Dream, is facing a shift. Young Americans are straying away from the driver's seat, and studies suggest we might have hit the peak of our car culture.\n",
    "\n",
    "But what does all this mean for the future? It means imagining a world with fewer parking garages and more green spaces, where the money saved on car maintenance fuels local economies or education instead. It means cleaner air and a chance for our planet to take a much-needed breath. It tells a tale of a society that puts wellness‚Äîboth environmental and personal‚Äîabove convenience.\n",
    "\n",
    "To wrap it up, envisioning a less car-dependent world is not about stripping away freedom; it's about rediscovering it in the shared spaces between our destinations. It's about making choices that ensure our health, the environment's safety, and ultimately, the security of our wallets. The evidence is in front of us, and the road ahead is clear. Detaching from automobile dependency can lead to thriving communities, healthier lifestyles, and economies with room to grow. Let's shift gears from a car-fueled present to a sustainable, connected future. Consider this: the next time you reach for your car keys, maybe, just maybe, it's worth considering the alternative.\"\"\"\n",
    "predict_on_cpu(text, tokenizer, model, INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.995194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.998916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.997219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.995194\n",
       "1  1111bbbb   0.998916\n",
       "2  2222cccc   0.997219"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = test_essays[['id', 'generated']]\n",
    "submission_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
